{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3f3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.9/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0c146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers.experimental.preprocessing import TextVectorization\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4dc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = pickle.load(open('data/train.pkl', 'rb'))\n",
    "valid_dict = pickle.load(open('data/valid.pkl', 'rb'))\n",
    "test_dict = pickle.load(open('data/test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd41c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Case Report','Diagnosis','Epidemic Forecasting','General Info',\n",
    "               'Mechanism','Prevention','Transmission','Treatment','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae1721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty \n",
    "\n",
    "def drop_empty(d:dict):\n",
    "    d_new = {i:d[i] for i in d if len(d[i]['embeddings']) != 0 and len(d[i]['lemmas']) != 0}\n",
    "    return d_new\n",
    "\n",
    "train = drop_empty(train_dict)\n",
    "valid = drop_empty(valid_dict)\n",
    "test = drop_empty(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd0141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5299e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c896849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.concatenate([train_dict[i]['embeddings'] for i in train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495b0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = embedding_matrix.shape[0]\n",
    "embedding_dim = embedding_matrix.shape[1]\n",
    "EPOCHS=10\n",
    "BATCH_SIZE=32\n",
    "LEARNING_RATE=0.001\n",
    "DROPOUT=0.7\n",
    "POOL_LENGTH=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6209c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         1087340100\n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 1,087,631,949\n",
      "Trainable params: 291,849\n",
      "Non-trainable params: 1,087,340,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_layer = Embedding(\n",
    "    input_dim = embedding_matrix.shape[0],\n",
    "    output_dim = embedding_matrix.shape[1],\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(DROPOUT)(x)\n",
    "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9199cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc6deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = [' '.join(train[i]['lemmas']) for i in train]\n",
    "val_samples = [' '.join(valid[i]['lemmas']) for i in valid]\n",
    "test_samples = [' '.join(test[i]['lemmas']) for i in test]\n",
    "\n",
    "# train_samples = [train[i]['input'] for i in train]\n",
    "# val_samples = [valid[i]['input'] for i in valid]\n",
    "# test_samples = [test[i]['input'] for i in test]\n",
    "\n",
    "train_labels = [train[i]['label_vec'] for i in train]\n",
    "val_labels = [valid[i]['label_vec'] for i in valid]\n",
    "test_labels = [test[i]['label_vec'] for i in test]\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=300)\n",
    "# text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(32)\n",
    "vectorizer.adapt(train_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b7b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "x_test = vectorizer(np.array([[s] for s in test_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e7ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf8ce970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1638/1638 [==============================] - 130s 72ms/step - loss: 1103009.5248 - acc: 0.1941 - precision: 0.2458 - recall: 0.1533 - F1_score: 0.2199 - my_auc: 0.5752 - val_loss: 11769236.0000 - val_acc: 0.3178 - val_precision: 0.3581 - val_recall: 0.2728 - val_F1_score: 0.3097 - val_my_auc: 0.5947\n",
      "Epoch 2/10\n",
      "1638/1638 [==============================] - 101s 62ms/step - loss: 30018226.0647 - acc: 0.1820 - precision: 0.2273 - recall: 0.1815 - F1_score: 0.2019 - my_auc: 0.5409 - val_loss: 89168696.0000 - val_acc: 0.1703 - val_precision: 0.1703 - val_recall: 0.1298 - val_F1_score: 0.1473 - val_my_auc: 0.5109\n",
      "Epoch 3/10\n",
      "1638/1638 [==============================] - 103s 63ms/step - loss: 112657642.0403 - acc: 0.1852 - precision: 0.2344 - recall: 0.1870 - F1_score: 0.2081 - my_auc: 0.5441 - val_loss: 100888384.0000 - val_acc: 0.2102 - val_precision: 0.2102 - val_recall: 0.1602 - val_F1_score: 0.1818 - val_my_auc: 0.5287\n",
      "Epoch 4/10\n",
      "1638/1638 [==============================] - 99s 60ms/step - loss: 245306091.1385 - acc: 0.1865 - precision: 0.2333 - recall: 0.1863 - F1_score: 0.2072 - my_auc: 0.5437 - val_loss: 398488672.0000 - val_acc: 0.3178 - val_precision: 0.3581 - val_recall: 0.2728 - val_F1_score: 0.3097 - val_my_auc: 0.5947\n",
      "Epoch 5/10\n",
      "1638/1638 [==============================] - 105s 64ms/step - loss: 447036913.3960 - acc: 0.1818 - precision: 0.2280 - recall: 0.1820 - F1_score: 0.2025 - my_auc: 0.5412 - val_loss: 355992896.0000 - val_acc: 0.3178 - val_precision: 0.3581 - val_recall: 0.2728 - val_F1_score: 0.3097 - val_my_auc: 0.5947\n",
      "Epoch 6/10\n",
      "1638/1638 [==============================] - 94s 57ms/step - loss: 686746424.6589 - acc: 0.1837 - precision: 0.2313 - recall: 0.1843 - F1_score: 0.2052 - my_auc: 0.5426 - val_loss: 581235264.0000 - val_acc: 0.1703 - val_precision: 0.1703 - val_recall: 0.1298 - val_F1_score: 0.1473 - val_my_auc: 0.5109\n",
      "Epoch 7/10\n",
      "1638/1638 [==============================] - 97s 59ms/step - loss: 997317455.3069 - acc: 0.1846 - precision: 0.2306 - recall: 0.1843 - F1_score: 0.2050 - my_auc: 0.5426 - val_loss: 678312896.0000 - val_acc: 0.3178 - val_precision: 0.3581 - val_recall: 0.2728 - val_F1_score: 0.3097 - val_my_auc: 0.5947\n",
      "Epoch 8/10\n",
      "1638/1638 [==============================] - 90s 55ms/step - loss: 1423179275.2459 - acc: 0.1853 - precision: 0.2329 - recall: 0.1858 - F1_score: 0.2067 - my_auc: 0.5434 - val_loss: 1323489920.0000 - val_acc: 0.0822 - val_precision: 0.2968 - val_recall: 0.2262 - val_F1_score: 0.2567 - val_my_auc: 0.5673\n",
      "Epoch 9/10\n",
      "1638/1638 [==============================] - 98s 60ms/step - loss: 1910497490.2355 - acc: 0.1908 - precision: 0.2366 - recall: 0.1890 - F1_score: 0.2103 - my_auc: 0.5453 - val_loss: 1327399296.0000 - val_acc: 0.0822 - val_precision: 0.2968 - val_recall: 0.2262 - val_F1_score: 0.2567 - val_my_auc: 0.5673\n",
      "Epoch 10/10\n",
      "1638/1638 [==============================] - 109s 67ms/step - loss: 2411215624.3563 - acc: 0.1855 - precision: 0.2304 - recall: 0.1847 - F1_score: 0.2051 - my_auc: 0.5428 - val_loss: 2523063296.0000 - val_acc: 0.3178 - val_precision: 0.3581 - val_recall: 0.2728 - val_F1_score: 0.3097 - val_my_auc: 0.5947\n",
      "CPU times: user 1h 6min 7s, sys: 14min 54s, total: 1h 21min 2s\n",
      "Wall time: 17min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2d8dee8b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# opt = SGD(lr=0.01)\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=opt, \n",
    "    metrics=[\"acc\", \n",
    "             metrics.Precision(), \n",
    "             tf.keras.metrics.Recall(), \n",
    "             tfa.metrics.F1Score(num_classes=len(class_names), average='micro', name='F1_score'),\n",
    "             metrics.AUC(name='my_auc')]\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa13bae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 3s 19ms/step - loss: 2523063296.0000 - acc: 0.3178 - precision: 0.3581 - recall: 0.2728 - F1_score: 0.3097 - my_auc: 0.5947\n",
      "Accuracy: 31.78%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c3d6fe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-78a3e5211205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796fdb68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
