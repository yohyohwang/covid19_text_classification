{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8769bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 15:27:06.440837: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-03 15:27:06.440931: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertModel,  AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")\n",
    "\n",
    "bertmodel = BertModel.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\", return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3de172e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import shutil, sys \n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec7abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52419, 14)\n",
      "(36052, 16)\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "print(train.shape)\n",
    "train = train.dropna(subset=['title', 'abstract']).reset_index()\n",
    "train[\"alltext\"] = train[\"title\"] + \" \"+ train[\"abstract\"]\n",
    "print(train.shape)\n",
    "valid = pd.read_csv('data/valid.csv')\n",
    "valid = valid.dropna(subset=['title', 'abstract']).reset_index()\n",
    "valid[\"alltext\"] = valid[\"title\"] + \" \"+ valid[\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6a44050",
   "metadata": {},
   "outputs": [],
   "source": [
    "    map_labels = {'Case Report': 0,\n",
    "              'Diagnosis': 1,\n",
    "              'Epidemic Forecasting': 2,\n",
    "              'General Info': 3,\n",
    "              'Mechanism': 4,\n",
    "              'Prevention': 5,\n",
    "              'Transmission': 6,\n",
    "              'Treatment': 7,\n",
    "              '': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ed598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_vect(df):\n",
    "    df = df.fillna('')\n",
    "\n",
    "    map_labels = {'Case Report': 0,\n",
    "              'Diagnosis': 1,\n",
    "              'Epidemic Forecasting': 2,\n",
    "              'General Info': 3,\n",
    "              'Mechanism': 4,\n",
    "              'Prevention': 5,\n",
    "              'Transmission': 6,\n",
    "              'Treatment': 7,\n",
    "              '': 8}\n",
    "\n",
    "    label_vec_idx = list()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "    \n",
    "        labels = df.loc[i, 'label'].split(';')\n",
    "        label_vec_idx.append(list(map(map_labels.get, labels)))\n",
    "\n",
    "    label_vec = [[0]*9 for i in range(len(label_vec_idx))]\n",
    "\n",
    "    for i in range(len(label_vec_idx)):\n",
    "        for j in label_vec_idx[i]:\n",
    "            label_vec[i][j] = 1\n",
    "        \n",
    "    df['label_vec'] = label_vec\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea2068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_labels_vect(train)\n",
    "valid = get_labels_vect(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516f6b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  train[\"alltext\"][1],\n",
    "  add_special_tokens=True,\n",
    "  max_length=512,\n",
    "  return_token_type_ids=False,\n",
    "  padding=\"max_length\",\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ecc406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = []\n",
    "for _, row in train.iterrows():\n",
    "  token_count = len(tokenizer.encode(\n",
    "    row[\"alltext\"], \n",
    "    max_length=512, \n",
    "    truncation=True\n",
    "  ))\n",
    "  token_counts.append(token_count)\n",
    "# tokenizing with respect to PubMedBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899bb135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 623., 1814., 3439., 4741., 5148., 5294., 5239., 4139., 2507.,\n",
       "        3108.]),\n",
       " array([ 13. ,  62.9, 112.8, 162.7, 212.6, 262.5, 312.4, 362.3, 412.2,\n",
       "        462.1, 512. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42295d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a class for this\n",
    "class TokensinDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data: pd.DataFrame, \n",
    "        tokenizer: tokenizer, \n",
    "        max_token_len: int = 512\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        alltext = data_row[\"alltext\"]\n",
    "        labels = data_row[\"label_vec\"]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            alltext,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        return dict(\n",
    "            alltext=alltext,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.FloatTensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c289ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TokensinDataset(\n",
    "    train,\n",
    "    tokenizer,\n",
    "    max_token_len=512\n",
    ")\n",
    "valid_dataset = TokensinDataset(\n",
    "    valid,\n",
    "    tokenizer,\n",
    "    max_token_len=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f51b099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alltext', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item = train_dataset[0]\n",
    "sample_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56abc011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Renin-Angiotensin-System (RAS) and COVID-19 - On The Prescription of RAS Blockers]. Twenty years ago, an enzyme homologous to the previously known angiotensin-converting enzyme (ACE) was identified, and subsequently named ACE2. In the renin-angiotensin system (RAS), ACE2 has counter-regulatory functions against the classical effector peptide angiotensin II, for example in blood pressure regulation and cardiovascular remodeling. However, ACE2 provides an initially unexpected interesting link between virology and cardiovascular medicine. That is, ACE2 represents the binding receptor for the cellular uptake of SARS-CoV and SARS-CoV-2 viruses. Thus, ACE2 is relevant for COVID-19. In this context, it was suspected that therapy with RAS blockers might promote transmission and complications of COVID-19 by upregulation of ACE2 expression. The aim of this short review is, to describe the link between the RAS, particularly ACE2, and COVID-19. Based on our analysis and evaluation of the available findings, we justify our conclusion: important drugs such as ACE inhibitors and angiotensin receptor blockers should continue to be prescribed according to guidelines to stable patients in the context of the COVID-19 pandemic.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item[\"alltext\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf3e482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c11ef8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2812191c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 512]), torch.Size([4, 512]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(DataLoader(train_dataset, batch_size=4, num_workers=0)))\n",
    "sample_batch[\"input_ids\"].shape, sample_batch[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce5d92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bertmodel(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5a75f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 512, 768]), torch.Size([4, 768]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape, output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ece35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load our data\n",
    "class textDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, test_df, tokenizer, batch_size=32, max_token_len=512):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = TokensinDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "        self.test_dataset = TokensinDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=6\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=6\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=6\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "329e2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_module = textDataModule(\n",
    "  train,\n",
    "  valid,\n",
    "  tokenizer,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  max_token_len=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b0f3c2",
   "metadata": {},
   "source": [
    "## Optimizer Scheduler\n",
    "\n",
    "So people apparently use this to get better results. This is a variable/changing optimizer that adjusts learning rate over time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d676683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/python/AML/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dummy_model = nn.Linear(2, 1)\n",
    "\n",
    "optimizer = AdamW(params=dummy_model.parameters(), lr=0.001) # this apparently is going to be deprecated soon\n",
    "# should use torch.optim.AdamW instead... but meh\n",
    "\n",
    "warmup_steps = 10\n",
    "total_training_steps = 100\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer, \n",
    "  num_warmup_steps=warmup_steps,\n",
    "  num_training_steps=total_training_steps\n",
    ")\n",
    "\n",
    "learning_rate_history = []\n",
    "\n",
    "for step in range(total_training_steps):\n",
    "  optimizer.step()\n",
    "  scheduler.step()\n",
    "  learning_rate_history.append(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bda9305e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate_history, label=\"learning rate\")\n",
    "plt.axvline(x=warmup_steps, color=\"red\", linestyle=(0, (5, 10)), label=\"warmup end\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e928ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 563)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch=len(train) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "warmup_steps = total_training_steps // 4\n",
    "warmup_steps, total_training_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "307c5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runnin our data\n",
    "class DatasetLabeler(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.bert = bertmodel\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "        output = torch.sigmoid(output)        \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "                loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        \n",
    "        labels = []\n",
    "        predictions = []\n",
    "        for output in outputs:\n",
    "            for out_labels in output[\"labels\"].detach().cpu():\n",
    "                labels.append(out_labels)\n",
    "            for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "                predictions.append(out_predictions)\n",
    "\n",
    "        labels = torch.stack(labels).int()\n",
    "        predictions = torch.stack(predictions)\n",
    "        map_labels = {'Case Report': 0,\n",
    "              'Diagnosis': 1,\n",
    "              'Epidemic Forecasting': 2,\n",
    "              'General Info': 3,\n",
    "              'Mechanism': 4,\n",
    "              'Prevention': 5,\n",
    "              'Transmission': 6,\n",
    "              'Treatment': 7,\n",
    "              '': 8}\n",
    "        LABEL_COLUMNS = map_labels.keys()\n",
    "        for i, name in enumerate(LABEL_COLUMNS):\n",
    "            class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
    "            self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # set up our optimizer\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.n_warmup_steps,\n",
    "            num_training_steps=self.n_training_steps\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=dict(\n",
    "                scheduler=scheduler,\n",
    "                interval='step'\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20fc52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    enable_checkpointing=checkpoint_callback,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    max_epochs=1,\n",
    "    enable_progress_bar=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36305912",
   "metadata": {},
   "source": [
    "## Running on a subset of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d29a22bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | bert       | BertModel | 109 M \n",
      "1 | classifier | Linear    | 6.9 K \n",
      "2 | criterion  | BCELoss   | 0     \n",
      "-----------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.957   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/python/AML/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1938: PossibleUserWarning: The number of training samples (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3681d8a22784a0f9a827d41c023c4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 13it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "test_dat_mod = textDataModule(\n",
    "  train.head(200),\n",
    "  valid.head(50),\n",
    "  tokenizer,\n",
    "  batch_size=32,\n",
    "  max_token_len=512\n",
    ")\n",
    "spe=len(train.head(200)) // BATCH_SIZE\n",
    "tts = spe * N_EPOCHS\n",
    "ws = tts // 4\n",
    "testmodel = DatasetLabeler(\n",
    "      n_classes=9,\n",
    "      n_warmup_steps=ws,\n",
    "      n_training_steps=tts \n",
    ")\n",
    "trainer.fit(testmodel, test_dat_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ee19266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [00:25<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = TokensinDataset(\n",
    "    valid.head(50),\n",
    "    tokenizer,\n",
    "    max_token_len=512\n",
    ")\n",
    "device = torch.device('cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(valid_dataset):\n",
    "  _, prediction = trained_model(\n",
    "    item[\"input_ids\"].unsqueeze(dim=0).to(device), \n",
    "    item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "  )\n",
    "  predictions.append(prediction.flatten())\n",
    "  labels.append(item[\"labels\"].int())\n",
    "\n",
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c71db82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6778)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = .5\n",
    "accuracy(predictions, labels, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4685b98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC per tag\n",
      "Case Report: 0.6530611515045166\n",
      "Diagnosis: 0.4195803999900818\n",
      "Epidemic Forecasting: 0.0\n",
      "General Info: 0.0\n",
      "Mechanism: 0.7412280440330505\n",
      "Prevention: 0.5294117331504822\n",
      "Transmission: 0.06122446060180664\n",
      "Treatment: 0.6362179517745972\n",
      ": 0.6976744532585144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/python/AML/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(\"AUROC per tag\")\n",
    "for i, name in enumerate(map_labels.keys()):\n",
    "  tag_auroc = auroc(predictions[:, i], labels[:, i], pos_label=1)\n",
    "  print(f\"{name}: {tag_auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "664627e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "         Case Report       0.03      1.00      0.06         1\n",
      "           Diagnosis       0.00      0.00      0.00        11\n",
      "Epidemic Forecasting       0.00      0.00      0.00         0\n",
      "        General Info       0.00      0.00      0.00         0\n",
      "           Mechanism       0.39      0.92      0.55        12\n",
      "          Prevention       0.40      0.12      0.19        16\n",
      "        Transmission       0.00      0.00      0.00         1\n",
      "           Treatment       0.50      0.04      0.08        24\n",
      "                           0.00      0.00      0.00         7\n",
      "\n",
      "           micro avg       0.15      0.21      0.17        72\n",
      "           macro avg       0.15      0.23      0.10        72\n",
      "        weighted avg       0.32      0.21      0.16        72\n",
      "         samples avg       0.10      0.20      0.13        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n",
    "\n",
    "upper, lower = 1, 0\n",
    "\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)\n",
    "\n",
    "print(classification_report(\n",
    "  y_true, \n",
    "  y_pred, \n",
    "  target_names=map_labels.keys()warmup_steps, total_training_steps, \n",
    "  zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c90b699",
   "metadata": {},
   "source": [
    "## Running this on the actual full datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab37c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "steps_per_epoch=len(train) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "warmup_steps = total_training_steps // 4\n",
    "warmup_steps, total_training_steps\n",
    "\n",
    "data_module = textDataModule(\n",
    "  train,\n",
    "  valid,\n",
    "  tokenizer,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  max_token_len=512\n",
    ")\n",
    "\n",
    "finmodel = DatasetLabeler(\n",
    "      n_classes=9,\n",
    "      n_warmup_steps=warmup_steps,\n",
    "      n_training_steps=total_training_steps \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5595e584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 563)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9bc6033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainerf = pl.Trainer(\n",
    "    enable_checkpointing=checkpoint_callback,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    max_epochs=N_EPOCHS,\n",
    "    enable_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7f5b7f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/python/AML/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | bert       | BertModel | 109 M \n",
      "1 | classifier | Linear    | 6.9 K \n",
      "2 | criterion  | BCELoss   | 0     \n",
      "-----------------------------------------\n",
      "6.9 K     Trainable params\n",
      "109 M     Non-trainable params\n",
      "109 M     Total params\n",
      "437.957   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd73d0ace75479188f275e103b6ab6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainerf.fit(finmodel, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21f08fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrained_model = DatasetLabeler.load_from_checkpoint(\n",
    "  trainerf.checkpoint_callback.best_model_path,\n",
    "  n_classes=9\n",
    ") #saved model stored from best_model_path\n",
    "ftrained_model.eval()\n",
    "ftrained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3e787e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "ftrained_model = ftrained_model.to(device)\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test = test.dropna(subset=['title', 'abstract']).reset_index()\n",
    "test[\"alltext\"] = test[\"title\"] + \" \"+ test[\"abstract\"]\n",
    "test = get_labels_vect(test)\n",
    "test_dataset = TokensinDataset(\n",
    "    test,\n",
    "    tokenizer,\n",
    "    max_token_len=512\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9f9f3b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5617/5617 [43:40<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(test_dataset):\n",
    "  _, prediction = ftrained_model(\n",
    "    item[\"input_ids\"].unsqueeze(dim=0).to(device), \n",
    "    item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "  )\n",
    "  predictions.append(prediction.flatten())\n",
    "  labels.append(item[\"labels\"].int())\n",
    "\n",
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "016eb059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "         Case Report       0.02      0.00      0.00       377\n",
      "           Diagnosis       0.34      0.13      0.19      1171\n",
      "Epidemic Forecasting       0.00      0.00      0.00       122\n",
      "        General Info       0.00      0.00      0.00        23\n",
      "           Mechanism       0.15      0.98      0.27       843\n",
      "          Prevention       0.36      1.00      0.53      2034\n",
      "        Transmission       0.03      0.21      0.06       187\n",
      "           Treatment       0.32      0.78      0.45      1649\n",
      "                           0.50      0.10      0.17       970\n",
      "\n",
      "           micro avg       0.26      0.60      0.36      7376\n",
      "           macro avg       0.19      0.36      0.19      7376\n",
      "        weighted avg       0.31      0.60      0.33      7376\n",
      "         samples avg       0.27      0.58      0.35      7376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n",
    "\n",
    "upper, lower = 1, 0\n",
    "\n",
    "## playing around with THRESHOLD\n",
    "THRESHOLD=0.3\n",
    "\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)\n",
    "\n",
    "print(classification_report(\n",
    "  y_true, \n",
    "  y_pred, \n",
    "  target_names=map_labels.keys(), \n",
    "  zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "17b1108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC per tag\n",
      "Case Report: 0.46999770402908325\n",
      "Diagnosis: 0.6217449903488159\n",
      "Epidemic Forecasting: 0.6770312786102295\n",
      "General Info: 0.7086941003799438\n",
      "Mechanism: 0.5576021671295166\n",
      "Prevention: 0.5999504327774048\n",
      "Transmission: 0.5208935141563416\n",
      "Treatment: 0.5718297958374023\n",
      ": 0.6864771842956543\n"
     ]
    }
   ],
   "source": [
    "print(\"AUROC per tag\")\n",
    "for i, name in enumerate(map_labels.keys()):\n",
    "  tag_auroc = auroc(predictions[:, i], labels[:, i], pos_label=1)\n",
    "  print(f\"{name}: {tag_auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8f8f1c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6951)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions, labels, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc05cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
